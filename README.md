# Sales-Conversion-Marketing-Funnel-Analysis
---
This project focuses on Conversion Rate Optimization (CRO) by analyzing the journey of a prospect from initial contact to final sale. By leveraging a combination of Python for deep-dive analytics and SQL for structured querying, this repository provides a blueprint for identifying "leaks" in a sales funnel.

---

## ðŸŽ¯ Business Objective
The goal of this project is to identify where potential customers drop off in the sales process and provide data-driven recommendations to increase the overall **Conversion Rate (CVR)**.

### ðŸŽ¯ Key Questions Addressed:
* **Friction Points:** Which stage of the funnel has the highest churn?
* **Segmentation:** Do specific demographics (Age, Education, Income) convert at significantly higher rates?
* **ROI:** Which marketing channels provide the highest quality leads?

---
## ðŸ“Œ Highlights

- ðŸ”„ Endâ€‘toâ€‘end workflow: **clean â†’ analyze â†’ visualize â†’ recommend**
- ðŸ“‰ Funnel metrics: stageâ€‘wise **conversion & dropâ€‘off rates**
- ðŸ§ª Statistical checks: correlation, significance tests, uplift hints
- ðŸ§¾ SQL recipes for fast insight queries
- ðŸ“Š Polished visuals for stakeholders

---

## ðŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ Data_exploration_cleaning.ipynb            # Ingest, clean, feature prep
â”œâ”€â”€ Exploratory_statistical_analysis.ipynb     # EDA, stats, correlations
â”œâ”€â”€ Visualization.ipynb                        # Funnel, cohorts, segments
â”œâ”€â”€ sql_tasks.sql                              # Reusable SQL insights
â”œâ”€â”€ cleaned_marketing_data.csv                 # Cleaned/processed data
â””â”€â”€ MARKETING_DATA.xls                         # Raw source (example)
```

## ðŸ› ï¸ Data Pipeline & Workflow

1.  **Data Cleaning (`Data_exploration_cleaning.ipynb`)**
    * Handled missing values and outliers in `MARKETING_DATA.xls`.
    * Feature engineering: Created "Days to Convert" and "Lead Score" metrics.
    * Exported `cleaned_marketing_data.csv` for downstream analysis.

2.  **Statistical Analysis (`Exploratory_statistical_analysis.ipynb`)**
    * Performed Correlation Matrix analysis to find drivers of conversion.
    * Conducted T-Tests/ANOVA to check if income levels significantly impact purchase behavior.

3.  **Advanced Visualization (`Visualization.ipynb`)**
    * Built **Funnel Charts** to visualize the leakages at each stage.
    * Created Cohort Analysis and Segmented Bar Charts for stakeholder reporting.

4.  **Database Integration (`Sql_task.sql`)**
    * Written optimized queries for rapid KPI extraction (e.g., Monthly Conversion Trends).

---

## ðŸ§° Tech Stack

- **Python**: pandas, numpy, scipy, scikitâ€‘learn (light), matplotlib, seaborn, plotly
- **SQL**: adâ€‘hoc analysis via `SQL Tasks.sql`
- **Jupyter Notebooks** for narrative analytics

> Optional extensions: **Power BI / Tableau**, **Streamlit/Dash** for interactive reporting.

---

Run in order:
1) `Data_exploration_cleaning.ipynb`  
2) `Exploratory_statistical_analysis.ipynb`  
3) `Visualization.ipynb`  
4) (Optional) Execute `sql_tasks.sql` in your SQL client.

---

## ðŸ§ª Typical Analyses Included

- **Data Quality**: missing values, outliers, type fixes, feature engineering
- **EDA**: distributions, bivariate analysis, correlation heatmaps
- **Funnel Views**: Awareness â†’ Interest â†’ Consideration â†’ Action
- **Segmentation**: channel, country, age, education, income
- **Stats**: proportion tests, confidence intervals, effectâ€‘size indicators
- **Visuals**: funnel charts, bar/line charts, box plots, cohort views

---

## ðŸ“Œ Reproducibility

- Notebooks are **ordered** for stepwise execution.
- Use a **seed** for stochastic steps where applicable.
- Keep raw vs cleaned data in **separate folders**.
- Document any **manual transformations** in the cleaning notebook.

---

## ðŸš€ How to Use
1. Clone the repository.
2. Install dependencies: `pip install pandas matplotlib seaborn plotly scipy`.
3. Run the notebooks in the numbered order: **Cleaning â†’ Stats â†’ Visualization**.
---
